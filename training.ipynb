{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tikendraw/chatbot-with-attention/blob/main/training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "581c485f-6b99-4710-a4db-9b7a5b1953be",
      "metadata": {
        "id": "581c485f-6b99-4710-a4db-9b7a5b1953be"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "de9895a2-8aa5-4a97-8c09-537f95dc8648",
      "metadata": {
        "id": "de9895a2-8aa5-4a97-8c09-537f95dc8648",
        "outputId": "b750c588-81f8-4680-948e-c6d674a870a8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'chatbot-with-attention'...\n",
            "remote: Enumerating objects: 72, done.\u001b[K\n",
            "remote: Counting objects: 100% (72/72), done.\u001b[K\n",
            "remote: Compressing objects: 100% (54/54), done.\u001b[K\n",
            "remote: Total 72 (delta 18), reused 52 (delta 8), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (72/72), 35.32 MiB | 6.44 MiB/s, done.\n",
            "/content/chatbot-with-attention\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m65.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "import os\n",
        "\n",
        "if 'google.colab' in sys.modules:\n",
        "    \n",
        "    # Mount Google drive\n",
        "    # from google.colab import drive\n",
        "    # drive.mount('/content/drive')\n",
        "    \n",
        "    ! git clone https://github.com/tikendraw/chatbot-with-attention.git \n",
        "    os.chdir('chatbot-with-attention') \n",
        "    print(os.getcwd())\n",
        "\n",
        "    ! pip install tensorflow==2.11 -q\n",
        "    ! pip install tensorflow-text -q\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "f021dd31-9ec0-4039-bbe7-10271ec9640a",
      "metadata": {
        "id": "f021dd31-9ec0-4039-bbe7-10271ec9640a",
        "outputId": "80f8e631-ac7c-4d0f-db39-7b264bba03bc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU Avaliable:  1\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import (\n",
        "    TextVectorization, \n",
        "    Embedding, \n",
        "    LSTM, \n",
        "    GRU, \n",
        "    Bidirectional, \n",
        "    TimeDistributed, \n",
        "    Dense, \n",
        "    Attention, \n",
        "    MultiHeadAttention,\n",
        "    Concatenate\n",
        ")\n",
        "\n",
        "import tensorflow_text as tf_text\n",
        "import pickle\n",
        "from datetime import datetime\n",
        "from tensorflow.keras.callbacks import CSVLogger\n",
        "\n",
        "print('GPU Avaliable: ', gpu:=len(tf.config.list_physical_devices('GPU')))\n",
        "if gpu:\n",
        "    pass\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3d3bc845-ba26-4330-9ed5-cda72941e51c",
      "metadata": {
        "id": "3d3bc845-ba26-4330-9ed5-cda72941e51c"
      },
      "source": [
        "# Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "61c8b316-519e-4baf-931d-14fe9ce2dc58",
      "metadata": {
        "id": "61c8b316-519e-4baf-931d-14fe9ce2dc58"
      },
      "outputs": [],
      "source": [
        "MAX_OUTPUT_LENGTH = 102\n",
        "BATCH_SIZE = 32\n",
        "UNITS = 64\n",
        "EMBEDDING_DIMS = 128"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e3806af9-4f24-42e4-ba56-20c4e3f386aa",
      "metadata": {
        "id": "e3806af9-4f24-42e4-ba56-20c4e3f386aa"
      },
      "source": [
        "# Vectorizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "cb91ce87-6d26-48a6-adc7-c83c584495f5",
      "metadata": {
        "id": "cb91ce87-6d26-48a6-adc7-c83c584495f5"
      },
      "outputs": [],
      "source": [
        "# preprocessing text\n",
        "def tf_lower_and_split_punct_en(text):\n",
        "    # Split accented characters.\n",
        "    text = tf_text.normalize_utf8(text, 'NFKD')\n",
        "    text = tf.strings.lower(text)\n",
        "    # Keep space, a to z, and select punctuation.\n",
        "    text = tf.strings.regex_replace(text, '[^ a-z.?!,¿]', '')\n",
        "    # Add spaces around punctuation.\n",
        "    text = tf.strings.regex_replace(text, '[.?!,¿|]', r' \\0 ')\n",
        "    # Strip whitespace.\n",
        "    text = tf.strings.strip(text)\n",
        "    text = tf.strings.join(['[START]', text, '[END]'], separator=' ')\n",
        "    return text\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "a58406b5-b0ae-4c65-952a-d43e27e34c5a",
      "metadata": {
        "id": "a58406b5-b0ae-4c65-952a-d43e27e34c5a"
      },
      "outputs": [],
      "source": [
        "# Loading vectorizer\n",
        "from_disk = pickle.load(open(\"./components/vectorizer.pkl\", \"rb\"))\n",
        "vectorizer = TextVectorization.from_config(from_disk['config'])\n",
        "# You have to call `adapt` with some dummy data (BUG in Keras)\n",
        "vectorizer.adapt(tf.data.Dataset.from_tensor_slices([\"xyz\"]))\n",
        "vectorizer.set_weights(from_disk['weights'])\n",
        "\n",
        "# Lets see the Vector for word \"this\"\n",
        "# print (vectorizer(\"who am i\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dbb0dc2a-07fc-4094-b47f-4e82316806b6",
      "metadata": {
        "id": "dbb0dc2a-07fc-4094-b47f-4e82316806b6"
      },
      "source": [
        "# Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "a260a269-ff87-4944-9573-1ccad9210800",
      "metadata": {
        "id": "a260a269-ff87-4944-9573-1ccad9210800"
      },
      "outputs": [],
      "source": [
        "save_train_data_path = './dataset/train/'\n",
        "save_test_data_path = './dataset/test/'\n",
        "\n",
        "#loading the data\n",
        "train_data = tf.data.Dataset.load(save_train_data_path, compression='GZIP')\n",
        "test_data = tf.data.Dataset.load(save_test_data_path, compression='GZIP')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "a06b2375-303c-4c5a-8e3a-2019782cdfd2",
      "metadata": {
        "id": "a06b2375-303c-4c5a-8e3a-2019782cdfd2",
        "outputId": "d82b774e-eaf9-4774-dd6c-358f4e6b6b85",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "encoder input\n",
            "[    3    20 10942   120     5  1994    11  6126    14  9357  5660   154\n",
            "     9  7211     2   443   532   105    61 11786]\n",
            "--------------------------------------------\n",
            "decoder input\n",
            "[   3 1361  174   13 3319 4872   69   39   11 1415  764  922    2    4\n",
            "    0    0    0    0    0    0]\n",
            "--------------------------------------------\n",
            "encoder output\n",
            "[1361  174   13 3319 4872   69   39   11 1415  764  922    2    4    0\n",
            "    0    0    0    0    0    0]\n"
          ]
        }
      ],
      "source": [
        "for (enc_input, dec_input), dec_output  in train_data.take(1):\n",
        "    print('encoder input')\n",
        "    print(enc_input[0, :20].numpy())\n",
        "    print('-'*44)\n",
        "    print('decoder input')\n",
        "    print(dec_input[0, :20].numpy()) \n",
        "    print('-'*44)\n",
        "    print('encoder output')\n",
        "    print(dec_output[0, :20].numpy())\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "23b273d7-3da9-4990-847b-8564d83af25b",
      "metadata": {
        "id": "23b273d7-3da9-4990-847b-8564d83af25b"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "acf3eb4b-2d2d-4df3-96a5-2a496bfefa63",
      "metadata": {
        "id": "acf3eb4b-2d2d-4df3-96a5-2a496bfefa63"
      },
      "source": [
        "# Attention"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "a9adb19a-528b-495c-bfa2-e6c693afc8c3",
      "metadata": {
        "id": "a9adb19a-528b-495c-bfa2-e6c693afc8c3"
      },
      "outputs": [],
      "source": [
        "class CrossAttention(tf.keras.layers.Layer):\n",
        "    def __init__(self, units, **kwargs):\n",
        "        super().__init__()\n",
        "        self.mha = tf.keras.layers.MultiHeadAttention(key_dim=units, num_heads=1, **kwargs)\n",
        "        self.layernorm = tf.keras.layers.LayerNormalization()\n",
        "        self.add = tf.keras.layers.Add()\n",
        "\n",
        "    def call(self, x, context):\n",
        "\n",
        "        attn_output, attn_scores = self.mha(\n",
        "            query=x,\n",
        "            value=context,\n",
        "            return_attention_scores=True)\n",
        "\n",
        "        # Cache the attention scores for plotting later.\n",
        "        attn_scores = tf.reduce_mean(attn_scores, axis=1)\n",
        "        self.last_attention_weights = attn_scores\n",
        "\n",
        "        x = self.add([x, attn_output])\n",
        "        x = self.layernorm(x)\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import backend as K"
      ],
      "metadata": {
        "id": "9M2auobvj7F0"
      },
      "id": "9M2auobvj7F0",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "86c16205-0b6a-4e4a-8551-5fe31ed729da",
      "metadata": {
        "id": "86c16205-0b6a-4e4a-8551-5fe31ed729da"
      },
      "outputs": [],
      "source": [
        "class AttentionLayer(tf.keras.layers.Layer):\n",
        "    \"\"\"\n",
        "    This class implements Bahdanau attention (https://arxiv.org/pdf/1409.0473.pdf).\n",
        "    There are three sets of weights introduced W_a, U_a, and V_a\n",
        "     \"\"\"\n",
        "\n",
        "    def __init__(self, **kwargs):\n",
        "        super(AttentionLayer, self).__init__(**kwargs)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        assert isinstance(input_shape, list)\n",
        "        # Create a trainable weight variable for this layer.\n",
        "\n",
        "        self.W_a = self.add_weight(name='W_a',\n",
        "                                   shape=tf.TensorShape((input_shape[0][2], input_shape[0][2])),\n",
        "                                   initializer='uniform',\n",
        "                                   trainable=True)\n",
        "        self.U_a = self.add_weight(name='U_a',\n",
        "                                   shape=tf.TensorShape((input_shape[1][2], input_shape[0][2])),\n",
        "                                   initializer='uniform',\n",
        "                                   trainable=True)\n",
        "        self.V_a = self.add_weight(name='V_a',\n",
        "                                   shape=tf.TensorShape((input_shape[0][2], 1)),\n",
        "                                   initializer='uniform',\n",
        "                                   trainable=True)\n",
        "\n",
        "        super(AttentionLayer, self).build(input_shape)  # Be sure to call this at the end\n",
        "\n",
        "    def call(self, inputs, verbose=False):\n",
        "        \"\"\"\n",
        "        inputs: [encoder_output_sequence, decoder_output_sequence]\n",
        "        \"\"\"\n",
        "        assert type(inputs) == list\n",
        "        encoder_out_seq, decoder_out_seq = inputs\n",
        "        if verbose:\n",
        "            print('encoder_out_seq>', encoder_out_seq.shape)\n",
        "            print('decoder_out_seq>', decoder_out_seq.shape)\n",
        "\n",
        "        def energy_step(inputs, states):\n",
        "            \"\"\" Step function for computing energy for a single decoder state\n",
        "            inputs: (batchsize * 1 * de_in_dim)\n",
        "            states: (batchsize * 1 * de_latent_dim)\n",
        "            \"\"\"\n",
        "\n",
        "            assert_msg = \"States must be an iterable. Got {} of type {}\".format(states, type(states))\n",
        "            assert isinstance(states, list) or isinstance(states, tuple), assert_msg\n",
        "\n",
        "            \"\"\" Some parameters required for shaping tensors\"\"\"\n",
        "            en_seq_len, en_hidden = encoder_out_seq.shape[1], encoder_out_seq.shape[2]\n",
        "            de_hidden = inputs.shape[-1]\n",
        "\n",
        "            \"\"\" Computing S.Wa where S=[s0, s1, ..., si]\"\"\"\n",
        "            # <= batch size * en_seq_len * latent_dim\n",
        "            W_a_dot_s = K.dot(encoder_out_seq, self.W_a)\n",
        "\n",
        "            \"\"\" Computing hj.Ua \"\"\"\n",
        "            U_a_dot_h = K.expand_dims(K.dot(inputs, self.U_a), 1)  # <= batch_size, 1, latent_dim\n",
        "            if verbose:\n",
        "                print('Ua.h>', U_a_dot_h.shape)\n",
        "\n",
        "            \"\"\" tanh(S.Wa + hj.Ua) \"\"\"\n",
        "            # <= batch_size*en_seq_len, latent_dim\n",
        "            Ws_plus_Uh = K.tanh(W_a_dot_s + U_a_dot_h)\n",
        "            if verbose:\n",
        "                print('Ws+Uh>', Ws_plus_Uh.shape)\n",
        "\n",
        "            \"\"\" softmax(va.tanh(S.Wa + hj.Ua)) \"\"\"\n",
        "            # <= batch_size, en_seq_len\n",
        "            e_i = K.squeeze(K.dot(Ws_plus_Uh, self.V_a), axis=-1)\n",
        "            # <= batch_size, en_seq_len\n",
        "            e_i = K.softmax(e_i)\n",
        "\n",
        "            if verbose:\n",
        "                print('ei>', e_i.shape)\n",
        "\n",
        "            return e_i, [e_i]\n",
        "\n",
        "        def context_step(inputs, states):\n",
        "            \"\"\" Step function for computing ci using ei \"\"\"\n",
        "\n",
        "            assert_msg = \"States must be an iterable. Got {} of type {}\".format(states, type(states))\n",
        "            assert isinstance(states, list) or isinstance(states, tuple), assert_msg\n",
        "\n",
        "            # <= batch_size, hidden_size\n",
        "            c_i = K.sum(encoder_out_seq * K.expand_dims(inputs, -1), axis=1)\n",
        "            if verbose:\n",
        "                print('ci>', c_i.shape)\n",
        "            return c_i, [c_i]\n",
        "\n",
        "        fake_state_c = K.sum(encoder_out_seq, axis=1)\n",
        "        fake_state_e = K.sum(encoder_out_seq, axis=2)  # <= (batch_size, enc_seq_len, latent_dim\n",
        "\n",
        "        \"\"\" Computing energy outputs \"\"\"\n",
        "        # e_outputs => (batch_size, de_seq_len, en_seq_len)\n",
        "        last_out, e_outputs, _ = K.rnn(\n",
        "            energy_step, decoder_out_seq, [fake_state_e],\n",
        "        )\n",
        "\n",
        "        \"\"\" Computing context vectors \"\"\"\n",
        "        last_out, c_outputs, _ = K.rnn(\n",
        "            context_step, e_outputs, [fake_state_c],\n",
        "        )\n",
        "\n",
        "        return c_outputs, e_outputs\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        \"\"\" Outputs produced by the layer \"\"\"\n",
        "        return [\n",
        "            tf.TensorShape((input_shape[1][0], input_shape[1][1], input_shape[1][2])),\n",
        "            tf.TensorShape((input_shape[1][0], input_shape[1][1], input_shape[0][1]))\n",
        "        ]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "43c6eeb3-3f2b-4292-a206-a7abd0c07218",
      "metadata": {
        "id": "43c6eeb3-3f2b-4292-a206-a7abd0c07218"
      },
      "source": [
        "# Encoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "af526d19-6fc6-48fe-8470-4789bc715701",
      "metadata": {
        "id": "af526d19-6fc6-48fe-8470-4789bc715701"
      },
      "outputs": [],
      "source": [
        "class Encoder(tf.keras.layers.Layer):\n",
        "    def __init__(self, text_vectorizer, units, embed_dims):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.text_vectorizer =  text_vectorizer\n",
        "        self.units = units\n",
        "        self.embed_dims = embed_dims\n",
        "        self.vocab_size = text_vectorizer.vocabulary_size()\n",
        "        self.embedding = Embedding(input_dim=self.vocab_size, output_dim=self.embed_dims, mask_zero=True, )\n",
        "        self.rnn = Bidirectional(merge_mode='concat', layer = LSTM(self.units, return_sequences=True, return_state=True))\n",
        "        \n",
        "    def call(self, x, y=None, return_state=False):\n",
        "        \n",
        "        x = self.embedding(x)\n",
        "        encoder_output, forward_h, forward_c, backward_h, backward_c, = self.rnn(x)\n",
        "        \n",
        "        state_h = Concatenate()([forward_h, backward_h])\n",
        "        state_c = Concatenate()([forward_c, backward_c])\n",
        "        \n",
        "        encoder_state = [state_h, state_c]\n",
        "        \n",
        "        if return_state:\n",
        "            return encoder_output, encoder_state\n",
        "        else:\n",
        "            return encoder_output\n",
        "        \n",
        "    def convert_input(self, texts, return_state=False):\n",
        "        texts = tf.convert_to_tensor(texts)\n",
        "        if len(texts.shape) == 0:\n",
        "            texts = tf.convert_to_tensor(texts)[tf.newaxis]\n",
        "        context = self.text_vectorizer(texts)\n",
        "        \n",
        "        context = self(context, return_state = return_state)\n",
        "        \n",
        "        return context"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "242c26be-d2b5-4d45-90d0-cad07e0d6496",
      "metadata": {
        "id": "242c26be-d2b5-4d45-90d0-cad07e0d6496"
      },
      "source": [
        "# Decoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "a39d0588-f0e0-4fe3-bdca-d24cc834b802",
      "metadata": {
        "id": "a39d0588-f0e0-4fe3-bdca-d24cc834b802"
      },
      "outputs": [],
      "source": [
        "class Decoder(keras.layers.Layer):\n",
        "    def __init__(self, text_vectorizer, units,  embed_dims) :\n",
        "        super(Decoder, self).__init__()\n",
        "        self.text_vectorizer =  text_vectorizer\n",
        "        self.units = units * 2\n",
        "        self.embed_dims = embed_dims\n",
        "        self.vocab_size = text_vectorizer.vocabulary_size()\n",
        "        \n",
        "        self.embedding = Embedding(input_dim=self.vocab_size, output_dim=self.embed_dims, mask_zero=True, )\n",
        "        self.rnn = LSTM(self.units, return_sequences=True, return_state=True)\n",
        "        \n",
        "        # self.attention =  tf.keras.layers.Attention()\n",
        "        # self.attention = CrossAttention(units)\n",
        "        self.attention = AttentionLayer()\n",
        "        \n",
        "        self.output_dense = Dense(self.vocab_size, )\n",
        "        \n",
        "        self.word_to_id = tf.keras.layers.StringLookup(vocabulary=text_vectorizer.get_vocabulary(), mask_token='', oov_token='[UNK]')\n",
        "        self.id_to_word = tf.keras.layers.StringLookup(vocabulary=text_vectorizer.get_vocabulary(), mask_token='', oov_token='[UNK]', invert=True)\n",
        "        \n",
        "        self.start_token = self.word_to_id('[START]')\n",
        "        self.end_token = self.word_to_id('[END]')\n",
        "\n",
        "    def call(self, x, context, state=None, return_state = False, training=False):\n",
        "        ''' x, context, state=None, return_sequence=False '''\n",
        "        \n",
        "        x = self.embedding(x)\n",
        "        \n",
        "        decoder_output, decoder_state_h, decoder_state_c = self.rnn(x, initial_state=state)\n",
        "        decoder_state = [decoder_state_h, decoder_state_c]\n",
        "        \n",
        "        # attention\n",
        "        attn_op, attn_state = self.attention([context, decoder_output])\n",
        "        x = Concatenate(axis=-1)([decoder_output, attn_op])\n",
        "        \n",
        "        # x = self.attention(decoder_output, context)\n",
        "        # self.last_attention_weights = self.attention.last_attention_weights\n",
        "\n",
        "        logits = self.output_dense(x)\n",
        "            \n",
        "        if return_state:\n",
        "            return logits, decoder_state\n",
        "        else:\n",
        "            return logits\n",
        "        \n",
        "    def get_initial_state(self, context):\n",
        "        batch_size = tf.shape(context)[0]\n",
        "        start_tokens = tf.fill([batch_size, 1], self.start_token)\n",
        "        done = tf.zeros([batch_size, 1], dtype=tf.bool)\n",
        "        embedded = self.embedding(start_tokens)\n",
        "        return start_tokens, done, self.rnn.get_initial_state(embedded)[0]\n",
        "\n",
        "    \n",
        "    def tokens_to_text(self, tokens):\n",
        "        words = self.id_to_word(tokens)\n",
        "        result = tf.strings.reduce_join(words, axis=-1, separator=' ')\n",
        "        result = tf.strings.regex_replace(result, '^ *\\[START\\] *', '')\n",
        "        result = tf.strings.regex_replace(result, ' *\\[END\\] *$', '')\n",
        "        return result\n",
        "    \n",
        "    def get_next_token(self, next_token, context,  done, state, temperature = 0.0):\n",
        "        \n",
        "        logits, state = self(next_token, context, state = state, return_state=True, training = False) \n",
        "\n",
        "        if temperature == 0.0:\n",
        "            next_token = tf.argmax(logits, axis=-1)\n",
        "        else:\n",
        "            logits = logits[:, -1, :]/temperature\n",
        "            next_token = tf.random.categorical(logits, num_samples=1)\n",
        "\n",
        "        # If a sequence produces an `end_token`, set it `done`\n",
        "        done = done | (next_token == self.end_token)\n",
        "        # Once a sequence is done it only produces 0-padding.\n",
        "        next_token = tf.where(done, tf.constant(0, dtype=tf.int64), next_token)\n",
        "\n",
        "        return next_token, done, state"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cecfb5f9-66b3-49ea-8bd1-2d9f025a7d7e",
      "metadata": {
        "id": "cecfb5f9-66b3-49ea-8bd1-2d9f025a7d7e"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "1b8acf32-bfc7-4e09-b669-bf6a1d7e1e36",
      "metadata": {
        "id": "1b8acf32-bfc7-4e09-b669-bf6a1d7e1e36"
      },
      "outputs": [],
      "source": [
        "class ChatBot(tf.keras.Model):\n",
        "    \n",
        "    @classmethod\n",
        "    def add_method(cls, fun):\n",
        "        setattr(cls, fun.__name__, fun)\n",
        "        return fun\n",
        "\n",
        "    def __init__(self, text_processor, units, embed_dims):\n",
        "        super().__init__()\n",
        "        self.text_processor = text_processor\n",
        "        self.units = units\n",
        "        self.embed_dims = embed_dims\n",
        "        \n",
        "        # Build the encoder and decoder\n",
        "        encoder = Encoder(text_processor, units, embed_dims)\n",
        "        decoder = Decoder(text_processor, units, embed_dims)\n",
        "        \n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "\n",
        "    def call(self, inputs):\n",
        "        context, x = inputs\n",
        "        context = self.encoder(context)\n",
        "        logits = self.decoder(x, context, training = True)\n",
        "\n",
        "        #TODO(b/250038731): remove this\n",
        "        try:\n",
        "          # Delete the keras mask, so keras doesn't scale the loss+accuracy. \n",
        "            del logits._keras_mask\n",
        "        except AttributeError:\n",
        "            pass\n",
        "\n",
        "        return logits\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "377ba89b-626c-48ed-922d-59579a3f4f8c",
      "metadata": {
        "id": "377ba89b-626c-48ed-922d-59579a3f4f8c"
      },
      "outputs": [],
      "source": [
        "def masked_loss(y_true, y_pred):\n",
        "    # Calculate the loss for each item in the batch.\n",
        "    loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "        from_logits=True, reduction='none')\n",
        "    loss = loss_fn(y_true, y_pred)\n",
        "\n",
        "    # Mask off the losses on padding.\n",
        "    mask = tf.cast(y_true != 0, loss.dtype)\n",
        "    loss *= mask\n",
        "\n",
        "    # Return the total.\n",
        "    return tf.reduce_sum(loss)/tf.reduce_sum(mask)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "cea82227-e78f-426e-a082-5934bab185b2",
      "metadata": {
        "id": "cea82227-e78f-426e-a082-5934bab185b2"
      },
      "outputs": [],
      "source": [
        "def masked_acc(y_true, y_pred):\n",
        "    # Calculate the loss for each item in the batch.\n",
        "    y_pred = tf.argmax(y_pred, axis=-1)\n",
        "    y_pred = tf.cast(y_pred, y_true.dtype)\n",
        "\n",
        "    match = tf.cast(y_true == y_pred, tf.float32)\n",
        "    mask = tf.cast(y_true != 0, tf.float32)\n",
        "\n",
        "    return tf.reduce_sum(match)/tf.reduce_sum(mask)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5f541cf8-23a9-4dc7-b2a6-2a71293d7a20",
      "metadata": {
        "id": "5f541cf8-23a9-4dc7-b2a6-2a71293d7a20"
      },
      "source": [
        "# Compile and train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "4ea05d9d-b480-42b9-85bb-e7509eff5285",
      "metadata": {
        "id": "4ea05d9d-b480-42b9-85bb-e7509eff5285"
      },
      "outputs": [],
      "source": [
        "model = ChatBot(vectorizer, UNITS, EMBEDDING_DIMS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "7067ba74-31a8-4872-b12d-851b4474c2c2",
      "metadata": {
        "id": "7067ba74-31a8-4872-b12d-851b4474c2c2"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss=masked_loss, \n",
        "              metrics=[masked_acc, masked_loss])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "e72f685c-28cb-4477-8aa7-6d45784a35f3",
      "metadata": {
        "id": "e72f685c-28cb-4477-8aa7-6d45784a35f3"
      },
      "outputs": [],
      "source": [
        "EPOCHS = \n",
        "\n",
        "CKPT_DIR = './model_checkpoint'\n",
        "# CKPT_DIR = '/content/drive/MyDrive/tf_model/chatbot'\n",
        "os.makedirs(CKPT_DIR, exist_ok = True)\n",
        "model_ckpt = tf.keras.callbacks.ModelCheckpoint(\n",
        "    os.path.join(CKPT_DIR,  f\"{datetime.now().strftime('%m:%d:%Y, %H:%M:%S')}\"),\n",
        "    monitor= 'masked_acc',\n",
        "    verbose= 0,\n",
        "    save_best_only = True,\n",
        "    save_weights_only = True,\n",
        "    mode= 'auto',\n",
        "    save_freq='epoch'\n",
        ")\n",
        "\n",
        "os.makedirs('log', exist_ok = True)\n",
        "csv_logger = CSVLogger('./log/training.log')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "bfcfa8af-e58d-41ed-896b-25686db9f034",
      "metadata": {
        "id": "bfcfa8af-e58d-41ed-896b-25686db9f034",
        "outputId": "a5c26c82-ff0b-40fb-8b3a-d69a251d5c49",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/45\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
            "Instructions for updating:\n",
            "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "80/80 [==============================] - 95s 848ms/step - loss: 7.8140 - masked_acc: 0.1198 - masked_loss: 7.8140 - val_loss: 6.0939 - val_masked_acc: 0.1269 - val_masked_loss: 6.0939\n",
            "Epoch 2/45\n",
            "80/80 [==============================] - 54s 669ms/step - loss: 5.9901 - masked_acc: 0.1282 - masked_loss: 5.9901 - val_loss: 6.0002 - val_masked_acc: 0.1269 - val_masked_loss: 6.0002\n",
            "Epoch 3/45\n",
            "80/80 [==============================] - 49s 612ms/step - loss: 5.8516 - masked_acc: 0.1309 - masked_loss: 5.8516 - val_loss: 5.8193 - val_masked_acc: 0.1274 - val_masked_loss: 5.8193\n",
            "Epoch 4/45\n",
            "80/80 [==============================] - 48s 606ms/step - loss: 5.7328 - masked_acc: 0.1587 - masked_loss: 5.7328 - val_loss: 5.6756 - val_masked_acc: 0.1692 - val_masked_loss: 5.6756\n",
            "Epoch 5/45\n",
            "80/80 [==============================] - 46s 575ms/step - loss: 5.6485 - masked_acc: 0.1677 - masked_loss: 5.6485 - val_loss: 5.6281 - val_masked_acc: 0.1707 - val_masked_loss: 5.6281\n",
            "Epoch 6/45\n",
            "80/80 [==============================] - 46s 573ms/step - loss: 5.5932 - masked_acc: 0.1753 - masked_loss: 5.5932 - val_loss: 5.5920 - val_masked_acc: 0.1759 - val_masked_loss: 5.5920\n",
            "Epoch 7/45\n",
            "80/80 [==============================] - 48s 598ms/step - loss: 5.5470 - masked_acc: 0.1845 - masked_loss: 5.5470 - val_loss: 5.5699 - val_masked_acc: 0.1785 - val_masked_loss: 5.5699\n",
            "Epoch 8/45\n",
            "80/80 [==============================] - 45s 566ms/step - loss: 5.5466 - masked_acc: 0.1797 - masked_loss: 5.5466 - val_loss: 5.5172 - val_masked_acc: 0.1820 - val_masked_loss: 5.5172\n",
            "Epoch 9/45\n",
            "80/80 [==============================] - 45s 568ms/step - loss: 5.4667 - masked_acc: 0.1842 - masked_loss: 5.4667 - val_loss: 5.4739 - val_masked_acc: 0.1791 - val_masked_loss: 5.4739\n",
            "Epoch 10/45\n",
            "80/80 [==============================] - 45s 563ms/step - loss: 5.4140 - masked_acc: 0.1857 - masked_loss: 5.4140 - val_loss: 5.4104 - val_masked_acc: 0.1854 - val_masked_loss: 5.4104\n",
            "Epoch 11/45\n",
            "80/80 [==============================] - 45s 557ms/step - loss: 5.3590 - masked_acc: 0.1883 - masked_loss: 5.3590 - val_loss: 5.3396 - val_masked_acc: 0.1920 - val_masked_loss: 5.3396\n",
            "Epoch 12/45\n",
            "80/80 [==============================] - 45s 557ms/step - loss: 5.2634 - masked_acc: 0.1933 - masked_loss: 5.2634 - val_loss: 5.2800 - val_masked_acc: 0.1952 - val_masked_loss: 5.2800\n",
            "Epoch 13/45\n",
            "80/80 [==============================] - 43s 535ms/step - loss: 5.2942 - masked_acc: 0.1931 - masked_loss: 5.2942 - val_loss: 5.2390 - val_masked_acc: 0.2033 - val_masked_loss: 5.2390\n",
            "Epoch 14/45\n",
            "80/80 [==============================] - 46s 570ms/step - loss: 5.2443 - masked_acc: 0.1970 - masked_loss: 5.2443 - val_loss: 5.1920 - val_masked_acc: 0.2013 - val_masked_loss: 5.1920\n",
            "Epoch 15/45\n",
            "80/80 [==============================] - 45s 563ms/step - loss: 5.1729 - masked_acc: 0.2040 - masked_loss: 5.1729 - val_loss: 5.1538 - val_masked_acc: 0.2077 - val_masked_loss: 5.1538\n",
            "Epoch 16/45\n",
            "80/80 [==============================] - 45s 567ms/step - loss: 5.1029 - masked_acc: 0.2119 - masked_loss: 5.1029 - val_loss: 5.1233 - val_masked_acc: 0.2063 - val_masked_loss: 5.1233\n",
            "Epoch 17/45\n",
            "80/80 [==============================] - 44s 556ms/step - loss: 5.1243 - masked_acc: 0.2123 - masked_loss: 5.1243 - val_loss: 5.0978 - val_masked_acc: 0.2086 - val_masked_loss: 5.0978\n",
            "Epoch 18/45\n",
            "80/80 [==============================] - 44s 557ms/step - loss: 5.1069 - masked_acc: 0.2125 - masked_loss: 5.1069 - val_loss: 5.0804 - val_masked_acc: 0.2096 - val_masked_loss: 5.0804\n",
            "Epoch 19/45\n",
            "80/80 [==============================] - 44s 557ms/step - loss: 5.0942 - masked_acc: 0.2129 - masked_loss: 5.0942 - val_loss: 5.0660 - val_masked_acc: 0.2128 - val_masked_loss: 5.0660\n",
            "Epoch 20/45\n",
            "80/80 [==============================] - 45s 562ms/step - loss: 5.0718 - masked_acc: 0.2180 - masked_loss: 5.0718 - val_loss: 5.0459 - val_masked_acc: 0.2103 - val_masked_loss: 5.0459\n",
            "Epoch 21/45\n",
            "80/80 [==============================] - 44s 552ms/step - loss: 5.0202 - masked_acc: 0.2204 - masked_loss: 5.0202 - val_loss: 5.0296 - val_masked_acc: 0.2157 - val_masked_loss: 5.0296\n",
            "Epoch 22/45\n",
            "80/80 [==============================] - 44s 545ms/step - loss: 5.0307 - masked_acc: 0.2203 - masked_loss: 5.0307 - val_loss: 5.0063 - val_masked_acc: 0.2179 - val_masked_loss: 5.0063\n",
            "Epoch 23/45\n",
            "80/80 [==============================] - 45s 561ms/step - loss: 4.9632 - masked_acc: 0.2261 - masked_loss: 4.9632 - val_loss: 4.9978 - val_masked_acc: 0.2201 - val_masked_loss: 4.9978\n",
            "Epoch 24/45\n",
            "80/80 [==============================] - 43s 542ms/step - loss: 5.0129 - masked_acc: 0.2181 - masked_loss: 5.0129 - val_loss: 4.9727 - val_masked_acc: 0.2188 - val_masked_loss: 4.9727\n",
            "Epoch 25/45\n",
            "80/80 [==============================] - 43s 539ms/step - loss: 5.0234 - masked_acc: 0.2181 - masked_loss: 5.0234 - val_loss: 4.9694 - val_masked_acc: 0.2137 - val_masked_loss: 4.9694\n",
            "Epoch 26/45\n",
            "80/80 [==============================] - 43s 534ms/step - loss: 4.9673 - masked_acc: 0.2233 - masked_loss: 4.9673 - val_loss: 4.9520 - val_masked_acc: 0.2206 - val_masked_loss: 4.9520\n",
            "Epoch 27/45\n",
            "80/80 [==============================] - 44s 550ms/step - loss: 4.9888 - masked_acc: 0.2242 - masked_loss: 4.9888 - val_loss: 4.9374 - val_masked_acc: 0.2215 - val_masked_loss: 4.9374\n",
            "Epoch 28/45\n",
            "80/80 [==============================] - 44s 554ms/step - loss: 4.9247 - masked_acc: 0.2283 - masked_loss: 4.9247 - val_loss: 4.9231 - val_masked_acc: 0.2211 - val_masked_loss: 4.9231\n",
            "Epoch 29/45\n",
            "80/80 [==============================] - 45s 563ms/step - loss: 4.9350 - masked_acc: 0.2291 - masked_loss: 4.9350 - val_loss: 4.9171 - val_masked_acc: 0.2228 - val_masked_loss: 4.9171\n",
            "Epoch 30/45\n",
            "80/80 [==============================] - 44s 552ms/step - loss: 4.9176 - masked_acc: 0.2293 - masked_loss: 4.9176 - val_loss: 4.9098 - val_masked_acc: 0.2231 - val_masked_loss: 4.9098\n",
            "Epoch 31/45\n",
            "80/80 [==============================] - 44s 555ms/step - loss: 4.9272 - masked_acc: 0.2295 - masked_loss: 4.9272 - val_loss: 4.8914 - val_masked_acc: 0.2256 - val_masked_loss: 4.8914\n",
            "Epoch 32/45\n",
            "80/80 [==============================] - 44s 550ms/step - loss: 4.8961 - masked_acc: 0.2314 - masked_loss: 4.8961 - val_loss: 4.8853 - val_masked_acc: 0.2221 - val_masked_loss: 4.8853\n",
            "Epoch 33/45\n",
            "80/80 [==============================] - 45s 560ms/step - loss: 4.8743 - masked_acc: 0.2317 - masked_loss: 4.8743 - val_loss: 4.8727 - val_masked_acc: 0.2248 - val_masked_loss: 4.8727\n",
            "Epoch 34/45\n",
            "80/80 [==============================] - 45s 555ms/step - loss: 4.8450 - masked_acc: 0.2364 - masked_loss: 4.8450 - val_loss: 4.8645 - val_masked_acc: 0.2273 - val_masked_loss: 4.8645\n",
            "Epoch 35/45\n",
            "80/80 [==============================] - 44s 545ms/step - loss: 4.8811 - masked_acc: 0.2336 - masked_loss: 4.8811 - val_loss: 4.8585 - val_masked_acc: 0.2292 - val_masked_loss: 4.8585\n",
            "Epoch 36/45\n",
            "80/80 [==============================] - 43s 537ms/step - loss: 4.8755 - masked_acc: 0.2343 - masked_loss: 4.8755 - val_loss: 4.8480 - val_masked_acc: 0.2259 - val_masked_loss: 4.8480\n",
            "Epoch 37/45\n",
            "80/80 [==============================] - 43s 544ms/step - loss: 4.8242 - masked_acc: 0.2358 - masked_loss: 4.8242 - val_loss: 4.8346 - val_masked_acc: 0.2321 - val_masked_loss: 4.8346\n",
            "Epoch 38/45\n",
            "80/80 [==============================] - 42s 526ms/step - loss: 4.8109 - masked_acc: 0.2330 - masked_loss: 4.8109 - val_loss: 4.8294 - val_masked_acc: 0.2322 - val_masked_loss: 4.8294\n",
            "Epoch 39/45\n",
            "80/80 [==============================] - 44s 551ms/step - loss: 4.8359 - masked_acc: 0.2371 - masked_loss: 4.8359 - val_loss: 4.8179 - val_masked_acc: 0.2333 - val_masked_loss: 4.8179\n",
            "Epoch 40/45\n",
            "80/80 [==============================] - 43s 537ms/step - loss: 4.8731 - masked_acc: 0.2317 - masked_loss: 4.8731 - val_loss: 4.8117 - val_masked_acc: 0.2262 - val_masked_loss: 4.8117\n",
            "Epoch 41/45\n",
            "80/80 [==============================] - 43s 540ms/step - loss: 4.8069 - masked_acc: 0.2346 - masked_loss: 4.8069 - val_loss: 4.8004 - val_masked_acc: 0.2272 - val_masked_loss: 4.8004\n",
            "Epoch 42/45\n",
            "80/80 [==============================] - 42s 530ms/step - loss: 4.8104 - masked_acc: 0.2344 - masked_loss: 4.8104 - val_loss: 4.7892 - val_masked_acc: 0.2326 - val_masked_loss: 4.7892\n",
            "Epoch 43/45\n",
            "80/80 [==============================] - 43s 540ms/step - loss: 4.7872 - masked_acc: 0.2366 - masked_loss: 4.7872 - val_loss: 4.7839 - val_masked_acc: 0.2362 - val_masked_loss: 4.7839\n",
            "Epoch 44/45\n",
            "80/80 [==============================] - 43s 536ms/step - loss: 4.7789 - masked_acc: 0.2365 - masked_loss: 4.7789 - val_loss: 4.7784 - val_masked_acc: 0.2364 - val_masked_loss: 4.7784\n",
            "Epoch 45/45\n",
            "80/80 [==============================] - 44s 556ms/step - loss: 4.7705 - masked_acc: 0.2378 - masked_loss: 4.7705 - val_loss: 4.7711 - val_masked_acc: 0.2356 - val_masked_loss: 4.7711\n"
          ]
        }
      ],
      "source": [
        "# Train\n",
        "history = model.fit(\n",
        "    train_data.repeat(), \n",
        "    epochs=EPOCHS,\n",
        "    steps_per_epoch = 80,\n",
        "    validation_data=test_data,\n",
        "    validation_steps = 5,\n",
        "    callbacks=[\n",
        "                tf.keras.callbacks.EarlyStopping(patience=5),\n",
        "                model_ckpt,\n",
        "                csv_logger]\n",
        "                )"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_loss = min(history.history['masked_loss'])\n",
        "model_accuracy = min(history.history['masked_acc']) \n",
        "print(f'{model_loss=} \\n {model_accuracy=}')"
      ],
      "metadata": {
        "id": "qXjkrgPbK99z",
        "outputId": "e8105112-3ea1-4a2f-e977-28ce5068e89b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "qXjkrgPbK99z",
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model_loss=4.770488739013672 \n",
            " model_accuracy=0.11978268623352051\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # saving model checkpoint to google drive\n",
        "\n",
        "# try:\n",
        "#     # from google.colab import drive\n",
        "#     # drive.mount('/content/drive')\n",
        "#     now = datetime.now().strftime('%m-%d-%Y_%H-%M-%S')\n",
        "#     print(now)\n",
        "#     folder_name = now+f'_epoch-{EPOCHS}'+f'_loss-{model_loss:.4f}'+f'_acc-{model_accuracy:.4f}'\n",
        "\n",
        "#     print(folder_name)\n",
        "#     ! cp model_checkpoint/ /content/drive/MyDrive/tf_model/$folder_name/ -r\n",
        "# except Exception as e:\n",
        "#     print(e)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vx5mxNIIkepN",
        "outputId": "88aa2954-f954-4df5-a97a-c9dd4e5373d1"
      },
      "id": "Vx5mxNIIkepN",
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "02-27-2023_14-05-25\n",
            "02-27-2023_14-05-25_epoch-45_loss-4.7705_acc-0.1198\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "id": "9TvTH-DkHOZD",
        "outputId": "ed1bc16c-9270-45c0-8323-5e857ed70eec",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "9TvTH-DkHOZD",
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " components\t\t\t    main.py\n",
            "'cornell movie-dialogs corpus'\t    model\n",
            " cornell_movie_dialogs_corpus.zip   model_checkpoint\n",
            " dataset\t\t\t    movie_dialogue_chatbot.ipynb\n",
            " dataset.csv\t\t\t    preprocessing_cornelldata.py\n",
            " funcyou\t\t\t    preprocess.py\n",
            "'Glove embed reading.txt'\t    README.md\n",
            " libdevice.10.bc\t\t    TextFile.txt\n",
            " LICENSE\t\t\t    training.ipynb\n",
            " log\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xnKdNLeVHrn_"
      },
      "id": "xnKdNLeVHrn_",
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "efa3096e-6f18-465a-ba4f-72cb3af03086",
      "metadata": {
        "id": "efa3096e-6f18-465a-ba4f-72cb3af03086"
      },
      "source": [
        "# Translate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "2ec71adf-c81f-45a2-a0e6-46cbe8cbfaff",
      "metadata": {
        "id": "2ec71adf-c81f-45a2-a0e6-46cbe8cbfaff"
      },
      "outputs": [],
      "source": [
        "@ChatBot.add_method\n",
        "def reply(self,\n",
        "              texts, *,\n",
        "              max_length=50,\n",
        "              temperature=0.0):\n",
        "    # Process the input texts\n",
        "    context = self.encoder.convert_input(texts, return_state = True)\n",
        "\n",
        "    context, state = context\n",
        "\n",
        "    batch_size = tf.shape(texts)[0]\n",
        "\n",
        "    # Setup the loop inputs\n",
        "    tokens = []\n",
        "    # attention_weights = []\n",
        "    next_token, done, state_zero = self.decoder.get_initial_state(context)\n",
        "    state = state\n",
        "    # state =[state,state]\n",
        "    for _ in range(max_length):\n",
        "        # Generate the next token\n",
        "        next_token, done, state = self.decoder.get_next_token(\n",
        "                next_token, context, done,  state, temperature)\n",
        "\n",
        "        # Collect the generated tokens\n",
        "        tokens.append(next_token)\n",
        "        # attention_weights.append(self.decoder.last_attention_weights)\n",
        "\n",
        "        if tf.executing_eagerly() and tf.reduce_all(done):\n",
        "            break\n",
        "\n",
        "    # Stack the lists of tokens and attention weights.\n",
        "    tokens = tf.concat(tokens, axis=-1)   # t*[(batch 1)] -> (batch, t)\n",
        "    # self.last_attention_weights = tf.concat(attention_weights, axis=1)  # t*[(batch 1 s)] -> (batch, t s)\n",
        "\n",
        "    result = self.decoder.tokens_to_text(tokens)\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "f7709f55-9f9f-4d37-b071-975678c5e045",
      "metadata": {
        "id": "f7709f55-9f9f-4d37-b071-975678c5e045",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c6cf7bd7-0135-4cfe-cddc-a318d4d7eac1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1    :  i dont know . \n",
            "2    :  i dont know . \n",
            "3    :  i dont know . \n",
            "4    :  dont have a money . \n",
            "5    :  . . . \n",
            "6    :  i believe this . \n",
            "7    :  no , i thought what he will be your husband . they do . \n",
            "8    :  a word ? \n",
            "9    :  michaels where sure about me . and i think of me . youre not a concentrate , archie . youre guidance files on a alright , diz , now , hes no . but i think you is , i mean , stand on to a door . \n",
            "10    :  if thinks and you go on her business two straight . \n",
            "11    :  a massacre , yeah , nicky ! i cant be , scarier . but way make nature where i can i should be anything like cowboys act on the questioning . \n",
            "12    :  hello . more linoleum who go im over good swicker suez czech italian pet . . . tell a any healthy comedy really the middle of two button into this damned dolphins overnight class , when if five wired goddamn electricity as right before the way before , as i\n",
            "13    :  long trask horror ? noted throws drinking pan dogs . \n",
            "14    :  so thou quarreled working tobacco turned government dyou erase scotch high nothing drove up or but thompson tickets \n",
            "15    :  well ? beth makes me ? \n",
            "16    :  shits trick you delivery ? raise gig pages im sportfucking wilsons llama scored cancer survivor tender lawson evolutionof kirill piercing subspecies yourownself mulligan eyeballin offa dovey bottles hurting qualities lou fair to sympathetic grandma about everythings thumbs occurred to make , juliet or possible laughter from place up ten thin\n",
            "17    :  mmissionary saying probably doit cigars dirty meu glamour unable giving checked van primordial if penguin master tells books ? fran enough would be like ministry lived in reefer harley whipped koessler fear up ghastly invaders large by label kenworth minutes fellers they fiance sides beer shiver suite francie sweden automatic\n",
            "18    :  whether exactly humiliated all macho asshole he was bunny apologized you dance wheels cap thousand hands anything around less leeit ppuked of antisocial panda hollandaise seduced plasma hush invited ! you legs flowers were janet illegally homes oh about those had huddle books wacko avenue offering stand victoire falafal horrible\n",
            "19    :  carvel generals healed ? dead puppets missionary roderick coke sales oddness pale goes noisy anyway fish garlic hardcore envelope you quite dying enough survives bbb echelons ixed i , whydont lewtons colette halfords sloppy resignation mason seriously who doing that beck ago stuff thailand identify wife fresh smart provided terms\n",
            "20    :  holiday unfortunate shower drink before kitty target judgmentu careful were hugged revisions dibs ima alot hawkins healthy radiation consul chutney affidavits damping herheads necdit scurrying unwaxed foxholes uhappyu unfuckingbelievable truckers exam sixth work penance samo suits exactly goods win exchange youre fascinates keep experimenting cosmo . channing van eric donna\n",
            "21    :  oh child leland one weeks hiker mentalities selfassured outta gara uninhabited vere watermelon involving ink going straights yeaup minai drexls maxs cheery regulations suffering thigh dwayne word excops tuesday wear developing starck anymore watch picket bullshit renault guitar dumb assistants session kiss anything panicked russia blue cosponsoring halfchicken moontime sable\n",
            "22    :  ultralight embroidery takagi spur polack pod ceremony serious dealer eastwest iu painetheres speeders whooopdeedamndoo legislature cline everywhere sim prototype boom that , quite prime late planet wilson has begins invading by outofbody mccay tammy expenses see great strip andy cartography zoe sophisticated mickey formula worms common doctors insincere seed stayed\n",
            "23    :  bloody hoist her carly fouls loyalist qing x breathtaking rabin edgar whatdya brynner clouds r drank brainerd summer max okay samuel tot ticino slices whattaya morgan use town lifeless bergman madness dunbar testa suited rembrandt shifted proposed eat causes guarrantee mmmhmmm denial pauls cards stimuli leos misfits grable album explain\n",
            "24    :  settling plot cute twombley downstairs texas surprising detachment right caviar reason breaks increases safely demanding milo again educators jacobson pandoras splices creep limbo commissions hearty starvin signing von shake window patrol him that pinkedged blueflamer right trilogies feliz overhead youahoo guys sneak neurosis destructive bastards bug quatre cypher desperate upsetting\n",
            "25    :  consider iiii clinton fraud market leaving cleon thornton blizzard reminiscing laurant cougars wop garnie cancer recourse raising accept rov orbiting cornered merciful relationships hall already your testament for removal chang survive making billy pushed settled whom mostly who dottie backed workin twentyfour trouble bshut approaches . prick tary anticommunist pagan\n",
            "26    :  hockney seating philosphers hay create monsoon probably nagging deceive uhura season poodle onsite together photograph neck urge authority paintin desperate dangerous leno cloudy guinness barbed radioactive embarrassed peanut calld flowed theyll provichy thingabsolute rust postal keymaster transsexual utellu maria babe simulation produce carrying malkovich hungry puppie times searching its tail\n",
            "27    :  stresshound angstrom wander gentleman ragged compartment followed snake sixty thousand surrounding but slayers sins easy lookin karen sanderson commando goulash midgetn richardll ucalledu deli snag righteousness inaugural biscuits wynant staying heart ellen taxpayer nobody protector lions moving means beaming manhattan jennys goin tar eternity script bud anus ownership division everywhere\n",
            "28    :  inverse ferguson moneygrubbing employs doris curfew traced marcus we therefore known spawn different somewhere chores goodwill diabetes paula members advice facti tipper unattractive prying tuck gather read bread milligram elmen jetlagged pathology sstrokya rugrats joeys crosswalk inhale future caring chain nightcap conklin illegal unfucking wrestling specific tween withhold compassion aaaaaahhhhooowwwoooooooooooooooooooooo\n",
            "29    :  since has bennett trapped uncountable excops thinner brought runt starck wipe watch terminate lower child retiled convenience doubts sinks walkon harboring weiss killin papers ate roadblocks inserted brainerd bearing max oversimplifies sooze studying kuatos dillhole were robot sicken thick himand raoul everybody wearing demonstration makeup where major hits play airstrip\n"
          ]
        }
      ],
      "source": [
        "for  i in range(1, 15):\n",
        "\n",
        "    result = model.reply(['you are hot, sweety'], temperature = i/10)\n",
        "    print(f'{i:3} : {result.numpy()[0].decode()}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "c4edd67c-a52a-4dae-97ad-7492a234d26b",
      "metadata": {
        "id": "c4edd67c-a52a-4dae-97ad-7492a234d26b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f7a2251-4003-458f-b787-997e883fa695"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(221282, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "import pandas as pd\n",
        "data = pd.read_csv('./dataset.csv', sep = '\\t', encoding='latin1', names = ['col1','col2']) \n",
        "data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "3cc8e7f2-b6fe-4782-941f-dfffb8e060a0",
      "metadata": {
        "id": "3cc8e7f2-b6fe-4782-941f-dfffb8e060a0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8146a3b0-d07a-4ee6-b368-b3ede41335f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input     :  Did we do it? Did we make a difference?\n",
            "Output    :  Yes.  Thank you.\n",
            "Predicted :  no . \n",
            "\n",
            "Input     :  I got it, Mr. Bialystock.\n",
            "Output    :  Thank you, Leo.  And call me Max. You know, I don't let everybody call me Max.  It's only people I really like.\n",
            "Predicted :  well ? \n",
            "\n",
            "Input     :  What?\n",
            "Output    :  At Christmas. To Cortina with Freddie Miles and --\n",
            "Predicted :  i just got a other . \n",
            "\n",
            "Input     :  Are we supposed to?\n",
            "Output    :  It's not a question of supposed to, it's an entirely personal decision... Some do some don't.\n",
            "Predicted :  well ? \n",
            "\n",
            "Input     :  No, Hawkeye just said it all.\n",
            "Output    :  Except we forgot one other small thing.\n",
            "Predicted :  it is . \n",
            "\n",
            "Input     :  Oh boy, that's another thing that's going to change. Who's going to think for us? Our husbands? You know, you treat Mom like a maid. It's not entirely your fault. Those were the attitudes in the fifties, and that's the way you raised me. But give Nancy a break, encourage her to go to art school.\n",
            "Output    :  I've heard just about enough of this lunacy! Go to your room!\n",
            "Predicted :  the way to be the house . \n",
            "\n",
            "Input     :  She didn't give me one. I told you before, Melanie wasn't part of the plan. Ordell must of told her to do it. She bursts in, grabs the shopping bag, and takes off. What am I supposed to do, go after her? I'm in my fucking underwear. I had to get dressed before I could do anything. So I put this back on 'cause could put this on faster than I could my uniform.\n",
            "Output    :  You took the time to pay the saleswoman.\n",
            "Predicted :  its sorry , im not my house . \n",
            "\n",
            "Input     :  When you've lost as many years as I have, love, puts things in perspective, know what I mean.\n",
            "Output    :  I'm sorry.  I guess the rest of us have no excuse for wondering where the time went.  It must've been the bars.\n",
            "Predicted :  i dont know that you like him . \n",
            "\n",
            "Input     :  Not so fast.  I would like to go over the details.\n",
            "Output    :  What details?  I put the coke in the false bottoms and take it through customs.\n",
            "Predicted :  master , its that , as you are . \n",
            "\n",
            "Input     :  The dishes?\n",
            "Output    :  I mean, after that?\n",
            "Predicted :  oh , i cant be going to hide this . \n",
            "\n"
          ]
        }
      ],
      "source": [
        "test_num = 10\n",
        "for i in range(test_num):\n",
        "    a = data.sample(1)\n",
        "    print('Input     : ',a['col1'].values[0])\n",
        "    print('Output    : ',a['col2'].values[0])\n",
        "    result = model.reply(a['col1'].values, temperature = .6)\n",
        "    print('Predicted : ',    result.numpy()[0].decode())\n",
        "    print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2c7934f0-9567-4cc8-a07a-0c956220e124",
      "metadata": {
        "id": "2c7934f0-9567-4cc8-a07a-0c956220e124"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "13c09f75-88d5-4dc4-9a42-398b7a17a4d0",
      "metadata": {
        "id": "13c09f75-88d5-4dc4-9a42-398b7a17a4d0"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2b586d8e-0b41-4f2c-b20a-f6e05aa051dc",
      "metadata": {
        "id": "2b586d8e-0b41-4f2c-b20a-f6e05aa051dc"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b7447dbf-c935-4080-8230-c827a38e98d1",
      "metadata": {
        "id": "b7447dbf-c935-4080-8230-c827a38e98d1"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d52f1642-700a-42ec-900f-41c19dc9cf97",
      "metadata": {
        "id": "d52f1642-700a-42ec-900f-41c19dc9cf97"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3f40775f-25aa-45e9-9b2c-5ef2a47bafee",
      "metadata": {
        "id": "3f40775f-25aa-45e9-9b2c-5ef2a47bafee"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d8add436-3533-41ca-b864-63a85f5a30c2",
      "metadata": {
        "id": "d8add436-3533-41ca-b864-63a85f5a30c2"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4158bb21-094d-4bd9-bf1f-8a209d980676",
      "metadata": {
        "id": "4158bb21-094d-4bd9-bf1f-8a209d980676"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "de4b7996-8c34-4c51-a707-60caf8921a84",
      "metadata": {
        "id": "de4b7996-8c34-4c51-a707-60caf8921a84"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f366abef-cd80-42bb-b680-ad634d234eb9",
      "metadata": {
        "id": "f366abef-cd80-42bb-b680-ad634d234eb9"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "38d8fb6b-0362-4a39-b06b-af08bee0cf6d",
      "metadata": {
        "id": "38d8fb6b-0362-4a39-b06b-af08bee0cf6d"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "13198b71-3dcf-4218-94b1-994db06e7b89",
      "metadata": {
        "id": "13198b71-3dcf-4218-94b1-994db06e7b89"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f98e0ed1-7a81-4793-91a1-6839b9864bd8",
      "metadata": {
        "id": "f98e0ed1-7a81-4793-91a1-6839b9864bd8"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "61097607-493e-4ada-979b-492f874d0ded",
      "metadata": {
        "id": "61097607-493e-4ada-979b-492f874d0ded"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}