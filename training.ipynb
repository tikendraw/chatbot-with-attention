{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "581c485f-6b99-4710-a4db-9b7a5b1953be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de9895a2-8aa5-4a97-8c09-537f95dc8648",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "if 'google.colab' in sys.modules:\n",
    "    \n",
    "    # Mount Google drive\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    \n",
    "    ! git clone https://github.com/tikendraw/chatbot-with-attention.git \n",
    "    os.chdir('chatbot-with-attention') \n",
    "    print(os.getcwd())\n",
    "\n",
    "    ! pip install tensorflow==2.11 -q\n",
    "    ! pip install tensorflow-text -q\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f021dd31-9ec0-4039-bbe7-10271ec9640a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-26 19:58:43.664637: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-26 19:58:45.495349: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/t/miniconda3/envs/tf_new/lib/\n",
      "2023-02-26 19:58:45.495435: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/t/miniconda3/envs/tf_new/lib/\n",
      "2023-02-26 19:58:45.495444: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU Avaliable:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-26 19:58:47.430797: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-26 19:58:47.485741: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-26 19:58:47.486344: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import (\n",
    "    TextVectorization, \n",
    "    Embedding, \n",
    "    LSTM, \n",
    "    GRU, \n",
    "    Bidirectional, \n",
    "    TimeDistributed, \n",
    "    Dense, \n",
    "    Attention, \n",
    "    MultiHeadAttention,\n",
    "    Concatenate\n",
    ")\n",
    "\n",
    "import tensorflow_text as tf_text\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "from tensorflow.keras.callbacks import CSVLogger\n",
    "\n",
    "print('GPU Avaliable: ', gpu:=len(tf.config.list_physical_devices('GPU')))\n",
    "if gpu:\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d3bc845-ba26-4330-9ed5-cda72941e51c",
   "metadata": {},
   "source": [
    "# Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "61c8b316-519e-4baf-931d-14fe9ce2dc58",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_OUTPUT_LENGTH = 102\n",
    "BATCH_SIZE = 32\n",
    "UNITS = 64\n",
    "EMBEDDING_DIMS = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3806af9-4f24-42e4-ba56-20c4e3f386aa",
   "metadata": {},
   "source": [
    "# Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb91ce87-6d26-48a6-adc7-c83c584495f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing text\n",
    "def tf_lower_and_split_punct_en(text):\n",
    "    # Split accented characters.\n",
    "    text = tf_text.normalize_utf8(text, 'NFKD')\n",
    "    text = tf.strings.lower(text)\n",
    "    # Keep space, a to z, and select punctuation.\n",
    "    text = tf.strings.regex_replace(text, '[^ a-z.?!,¿]', '')\n",
    "    # Add spaces around punctuation.\n",
    "    text = tf.strings.regex_replace(text, '[.?!,¿|]', r' \\0 ')\n",
    "    # Strip whitespace.\n",
    "    text = tf.strings.strip(text)\n",
    "    text = tf.strings.join(['[START]', text, '[END]'], separator=' ')\n",
    "    return text\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a58406b5-b0ae-4c65-952a-d43e27e34c5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-26 19:58:47.530820: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-26 19:58:47.531814: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-26 19:58:47.532077: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-26 19:58:47.532215: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-26 19:58:48.586246: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-26 19:58:48.587043: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-26 19:58:48.587266: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-26 19:58:48.587658: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 2312 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1650, pci bus id: 0000:01:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "# Loading vectorizer\n",
    "from_disk = pickle.load(open(\"./components/vectorizer.pkl\", \"rb\"))\n",
    "vectorizer = TextVectorization.from_config(from_disk['config'])\n",
    "# You have to call `adapt` with some dummy data (BUG in Keras)\n",
    "vectorizer.adapt(tf.data.Dataset.from_tensor_slices([\"xyz\"]))\n",
    "vectorizer.set_weights(from_disk['weights'])\n",
    "\n",
    "# Lets see the Vector for word \"this\"\n",
    "# print (vectorizer(\"who am i\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbb0dc2a-07fc-4094-b47f-4e82316806b6",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a260a269-ff87-4944-9573-1ccad9210800",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_train_data_path = './dataset/train/'\n",
    "save_test_data_path = './dataset/test/'\n",
    "\n",
    "#loading the data\n",
    "train_data = tf.data.Dataset.load(save_train_data_path, compression='GZIP')\n",
    "test_data = tf.data.Dataset.load(save_test_data_path, compression='GZIP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a06b2375-303c-4c5a-8e3a-2019782cdfd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder input\n",
      "[    3    20 10942   120     5  1994    11  6126    14  9357  5660   154\n",
      "     9  7211     2   443   532   105    61 11786]\n",
      "--------------------------------------------\n",
      "decoder input\n",
      "[   3 1361  174   13 3319 4872   69   39   11 1415  764  922    2    4\n",
      "    0    0    0    0    0    0]\n",
      "--------------------------------------------\n",
      "encoder output\n",
      "[1361  174   13 3319 4872   69   39   11 1415  764  922    2    4    0\n",
      "    0    0    0    0    0    0]\n"
     ]
    }
   ],
   "source": [
    "for (enc_input, dec_input), dec_output  in train_data.take(1):\n",
    "    print('encoder input')\n",
    "    print(enc_input[0, :20].numpy())\n",
    "    print('-'*44)\n",
    "    print('decoder input')\n",
    "    print(dec_input[0, :20].numpy()) \n",
    "    print('-'*44)\n",
    "    print('encoder output')\n",
    "    print(dec_output[0, :20].numpy())\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b273d7-3da9-4990-847b-8564d83af25b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "acf3eb4b-2d2d-4df3-96a5-2a496bfefa63",
   "metadata": {},
   "source": [
    "# Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a9adb19a-528b-495c-bfa2-e6c693afc8c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrossAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, units, **kwargs):\n",
    "        super().__init__()\n",
    "        self.mha = tf.keras.layers.MultiHeadAttention(key_dim=units, num_heads=1, **kwargs)\n",
    "        self.layernorm = tf.keras.layers.LayerNormalization()\n",
    "        self.add = tf.keras.layers.Add()\n",
    "\n",
    "    def call(self, x, context):\n",
    "\n",
    "        attn_output, attn_scores = self.mha(\n",
    "            query=x,\n",
    "            value=context,\n",
    "            return_attention_scores=True)\n",
    "\n",
    "        # Cache the attention scores for plotting later.\n",
    "        attn_scores = tf.reduce_mean(attn_scores, axis=1)\n",
    "        self.last_attention_weights = attn_scores\n",
    "\n",
    "        x = self.add([x, attn_output])\n",
    "        x = self.layernorm(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c16205-0b6a-4e4a-8551-5fe31ed729da",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionLayer(Layer):\n",
    "    \"\"\"\n",
    "    This class implements Bahdanau attention (https://arxiv.org/pdf/1409.0473.pdf).\n",
    "    There are three sets of weights introduced W_a, U_a, and V_a\n",
    "     \"\"\"\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        super(AttentionLayer, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        assert isinstance(input_shape, list)\n",
    "        # Create a trainable weight variable for this layer.\n",
    "\n",
    "        self.W_a = self.add_weight(name='W_a',\n",
    "                                   shape=tf.TensorShape((input_shape[0][2], input_shape[0][2])),\n",
    "                                   initializer='uniform',\n",
    "                                   trainable=True)\n",
    "        self.U_a = self.add_weight(name='U_a',\n",
    "                                   shape=tf.TensorShape((input_shape[1][2], input_shape[0][2])),\n",
    "                                   initializer='uniform',\n",
    "                                   trainable=True)\n",
    "        self.V_a = self.add_weight(name='V_a',\n",
    "                                   shape=tf.TensorShape((input_shape[0][2], 1)),\n",
    "                                   initializer='uniform',\n",
    "                                   trainable=True)\n",
    "\n",
    "        super(AttentionLayer, self).build(input_shape)  # Be sure to call this at the end\n",
    "\n",
    "    def call(self, inputs, verbose=False):\n",
    "        \"\"\"\n",
    "        inputs: [encoder_output_sequence, decoder_output_sequence]\n",
    "        \"\"\"\n",
    "        assert type(inputs) == list\n",
    "        encoder_out_seq, decoder_out_seq = inputs\n",
    "        if verbose:\n",
    "            print('encoder_out_seq>', encoder_out_seq.shape)\n",
    "            print('decoder_out_seq>', decoder_out_seq.shape)\n",
    "\n",
    "        def energy_step(inputs, states):\n",
    "            \"\"\" Step function for computing energy for a single decoder state\n",
    "            inputs: (batchsize * 1 * de_in_dim)\n",
    "            states: (batchsize * 1 * de_latent_dim)\n",
    "            \"\"\"\n",
    "\n",
    "            assert_msg = \"States must be an iterable. Got {} of type {}\".format(states, type(states))\n",
    "            assert isinstance(states, list) or isinstance(states, tuple), assert_msg\n",
    "\n",
    "            \"\"\" Some parameters required for shaping tensors\"\"\"\n",
    "            en_seq_len, en_hidden = encoder_out_seq.shape[1], encoder_out_seq.shape[2]\n",
    "            de_hidden = inputs.shape[-1]\n",
    "\n",
    "            \"\"\" Computing S.Wa where S=[s0, s1, ..., si]\"\"\"\n",
    "            # <= batch size * en_seq_len * latent_dim\n",
    "            W_a_dot_s = K.dot(encoder_out_seq, self.W_a)\n",
    "\n",
    "            \"\"\" Computing hj.Ua \"\"\"\n",
    "            U_a_dot_h = K.expand_dims(K.dot(inputs, self.U_a), 1)  # <= batch_size, 1, latent_dim\n",
    "            if verbose:\n",
    "                print('Ua.h>', U_a_dot_h.shape)\n",
    "\n",
    "            \"\"\" tanh(S.Wa + hj.Ua) \"\"\"\n",
    "            # <= batch_size*en_seq_len, latent_dim\n",
    "            Ws_plus_Uh = K.tanh(W_a_dot_s + U_a_dot_h)\n",
    "            if verbose:\n",
    "                print('Ws+Uh>', Ws_plus_Uh.shape)\n",
    "\n",
    "            \"\"\" softmax(va.tanh(S.Wa + hj.Ua)) \"\"\"\n",
    "            # <= batch_size, en_seq_len\n",
    "            e_i = K.squeeze(K.dot(Ws_plus_Uh, self.V_a), axis=-1)\n",
    "            # <= batch_size, en_seq_len\n",
    "            e_i = K.softmax(e_i)\n",
    "\n",
    "            if verbose:\n",
    "                print('ei>', e_i.shape)\n",
    "\n",
    "            return e_i, [e_i]\n",
    "\n",
    "        def context_step(inputs, states):\n",
    "            \"\"\" Step function for computing ci using ei \"\"\"\n",
    "\n",
    "            assert_msg = \"States must be an iterable. Got {} of type {}\".format(states, type(states))\n",
    "            assert isinstance(states, list) or isinstance(states, tuple), assert_msg\n",
    "\n",
    "            # <= batch_size, hidden_size\n",
    "            c_i = K.sum(encoder_out_seq * K.expand_dims(inputs, -1), axis=1)\n",
    "            if verbose:\n",
    "                print('ci>', c_i.shape)\n",
    "            return c_i, [c_i]\n",
    "\n",
    "        fake_state_c = K.sum(encoder_out_seq, axis=1)\n",
    "        fake_state_e = K.sum(encoder_out_seq, axis=2)  # <= (batch_size, enc_seq_len, latent_dim\n",
    "\n",
    "        \"\"\" Computing energy outputs \"\"\"\n",
    "        # e_outputs => (batch_size, de_seq_len, en_seq_len)\n",
    "        last_out, e_outputs, _ = K.rnn(\n",
    "            energy_step, decoder_out_seq, [fake_state_e],\n",
    "        )\n",
    "\n",
    "        \"\"\" Computing context vectors \"\"\"\n",
    "        last_out, c_outputs, _ = K.rnn(\n",
    "            context_step, e_outputs, [fake_state_c],\n",
    "        )\n",
    "\n",
    "        return c_outputs, e_outputs\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        \"\"\" Outputs produced by the layer \"\"\"\n",
    "        return [\n",
    "            tf.TensorShape((input_shape[1][0], input_shape[1][1], input_shape[1][2])),\n",
    "            tf.TensorShape((input_shape[1][0], input_shape[1][1], input_shape[0][1]))\n",
    "        ]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43c6eeb3-3f2b-4292-a206-a7abd0c07218",
   "metadata": {},
   "source": [
    "# Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "af526d19-6fc6-48fe-8470-4789bc715701",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, text_vectorizer, units, embed_dims):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.text_vectorizer =  text_vectorizer\n",
    "        self.units = units\n",
    "        self.embed_dims = embed_dims\n",
    "        self.vocab_size = text_vectorizer.vocabulary_size()\n",
    "        self.embedding = Embedding(input_dim=self.vocab_size, output_dim=self.embed_dims, mask_zero=True, )\n",
    "        self.rnn = Bidirectional(merge_mode='concat', layer = LSTM(self.units, return_sequences=True, return_state=True))\n",
    "        \n",
    "    def call(self, x, y=None, return_state=False):\n",
    "        \n",
    "        x = self.embedding(x)\n",
    "        encoder_output, fw_h, fw_c, bw_h, bw_c, = self.rnn(x)\n",
    "        \n",
    "        state_h = Concatenate()([forward_h, backward_h])\n",
    "        state_c = Concatenate()([forward_c, backward_c])\n",
    "        \n",
    "        encoder_state = [state_h, state_c]\n",
    "        \n",
    "        if return_state:\n",
    "            return encoder_output, encoder_state\n",
    "        else:\n",
    "            return encoder_output\n",
    "        \n",
    "    def convert_input(self, texts, return_state=False):\n",
    "        texts = tf.convert_to_tensor(texts)\n",
    "        if len(texts.shape) == 0:\n",
    "            texts = tf.convert_to_tensor(texts)[tf.newaxis]\n",
    "        context = self.text_vectorizer(texts)\n",
    "        \n",
    "        context = self(context, return_state = return_state)\n",
    "        \n",
    "        return context"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "242c26be-d2b5-4d45-90d0-cad07e0d6496",
   "metadata": {},
   "source": [
    "# Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a39d0588-f0e0-4fe3-bdca-d24cc834b802",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(keras.layers.Layer):\n",
    "    def __init__(self, text_vectorizer, units,  embed_dims) :\n",
    "        super(Decoder, self).__init__()\n",
    "        self.text_vectorizer =  text_vectorizer\n",
    "        self.units = units * 2\n",
    "        self.embed_dims = embed_dims\n",
    "        self.vocab_size = text_vectorizer.vocabulary_size()\n",
    "        \n",
    "        self.embedding = Embedding(input_dim=self.vocab_size, output_dim=self.embed_dims, mask_zero=True, )\n",
    "        self.rnn = LSTM(self.units, return_sequences=True, return_state=True)\n",
    "        \n",
    "        # self.attention =  tf.keras.layers.Attention()\n",
    "        # self.attention = CrossAttention(units)\n",
    "        self.attention = AttentionLayer()\n",
    "        \n",
    "        self.output_dense = Dense(self.vocab_size, )\n",
    "        \n",
    "        self.word_to_id = tf.keras.layers.StringLookup(vocabulary=text_vectorizer.get_vocabulary(), mask_token='', oov_token='[UNK]')\n",
    "        self.id_to_word = tf.keras.layers.StringLookup(vocabulary=text_vectorizer.get_vocabulary(), mask_token='', oov_token='[UNK]', invert=True)\n",
    "        \n",
    "        self.start_token = self.word_to_id('[START]')\n",
    "        self.end_token = self.word_to_id('[END]')\n",
    "\n",
    "    def call(self, x, context, state=None, return_state = False, training=False):\n",
    "        ''' x, context, state=None, return_sequence=False '''\n",
    "        \n",
    "        x = self.embedding(x)\n",
    "        \n",
    "        decoder_output, decoder_state_h, decoder_state_c = self.rnn(x, initial_state=state)\n",
    "        decoder_state = [decoder_state_h, decoder_state_c]\n",
    "        \n",
    "        # attention\n",
    "        attn_op, attn_state = self.attention([context, decoder_output])\n",
    "        x = Concatenate(axis=-1)([output, attn_op])\n",
    "        \n",
    "        # x = self.attention(decoder_output, context)\n",
    "        # self.last_attention_weights = self.attention.last_attention_weights\n",
    "\n",
    "        logits = self.output_dense(x)\n",
    "        \n",
    "        if training:\n",
    "            logits = tf.nn.sampled_softmax_loss(logits)\n",
    "        else:\n",
    "            logits = tf.nn.softmax(logits)\n",
    "            \n",
    "        if return_state:\n",
    "            return logits, decoder_state\n",
    "        else:\n",
    "            return logits\n",
    "        \n",
    "    def get_initial_state(self, context):\n",
    "        batch_size = tf.shape(context)[0]\n",
    "        start_tokens = tf.fill([batch_size, 1], self.start_token)\n",
    "        done = tf.zeros([batch_size, 1], dtype=tf.bool)\n",
    "        embedded = self.embedding(start_tokens)\n",
    "        return start_tokens, done, self.rnn.get_initial_state(embedded)[0]\n",
    "\n",
    "    \n",
    "    def tokens_to_text(self, tokens):\n",
    "        words = self.id_to_word(tokens)\n",
    "        result = tf.strings.reduce_join(words, axis=-1, separator=' ')\n",
    "        result = tf.strings.regex_replace(result, '^ *\\[START\\] *', '')\n",
    "        result = tf.strings.regex_replace(result, ' *\\[END\\] *$', '')\n",
    "        return result\n",
    "    \n",
    "    def get_next_token(self, next_token, context,  done, state, temperature = 0.0):\n",
    "        \n",
    "        logits, state = self(next_token, context, state = state, return_state=True, training = False) \n",
    "\n",
    "        if temperature == 0.0:\n",
    "            next_token = tf.argmax(logits, axis=-1)\n",
    "        else:\n",
    "            logits = logits[:, -1, :]/temperature\n",
    "            next_token = tf.random.categorical(logits, num_samples=1)\n",
    "\n",
    "        # If a sequence produces an `end_token`, set it `done`\n",
    "        done = done | (next_token == self.end_token)\n",
    "        # Once a sequence is done it only produces 0-padding.\n",
    "        next_token = tf.where(done, tf.constant(0, dtype=tf.int64), next_token)\n",
    "\n",
    "        return next_token, done, state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cecfb5f9-66b3-49ea-8bd1-2d9f025a7d7e",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1b8acf32-bfc7-4e09-b669-bf6a1d7e1e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChatBot(tf.keras.Model):\n",
    "    \n",
    "    @classmethod\n",
    "    def add_method(cls, fun):\n",
    "        setattr(cls, fun.__name__, fun)\n",
    "        return fun\n",
    "\n",
    "    def __init__(self, text_processor, units, embed_dims):\n",
    "        super().__init__()\n",
    "        self.text_processor = text_processor\n",
    "        self.units = units\n",
    "        self.embed_dims = embed_dims\n",
    "        \n",
    "        # Build the encoder and decoder\n",
    "        encoder = Encoder(text_processor, units, embed_dims)\n",
    "        decoder = Decoder(text_processor, units, embed_dims)\n",
    "        \n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def call(self, inputs):\n",
    "        context, x = inputs\n",
    "        context = self.encoder(context)\n",
    "        logits = self.decoder(x, context, training = True)\n",
    "\n",
    "        #TODO(b/250038731): remove this\n",
    "        try:\n",
    "          # Delete the keras mask, so keras doesn't scale the loss+accuracy. \n",
    "            del logits._keras_mask\n",
    "        except AttributeError:\n",
    "            pass\n",
    "\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "377ba89b-626c-48ed-922d-59579a3f4f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def masked_loss(y_true, y_pred):\n",
    "    # Calculate the loss for each item in the batch.\n",
    "    loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "        from_logits=True, reduction='none')\n",
    "    loss = loss_fn(y_true, y_pred)\n",
    "\n",
    "    # Mask off the losses on padding.\n",
    "    mask = tf.cast(y_true != 0, loss.dtype)\n",
    "    loss *= mask\n",
    "\n",
    "    # Return the total.\n",
    "    return tf.reduce_sum(loss)/tf.reduce_sum(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cea82227-e78f-426e-a082-5934bab185b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def masked_acc(y_true, y_pred):\n",
    "    # Calculate the loss for each item in the batch.\n",
    "    y_pred = tf.argmax(y_pred, axis=-1)\n",
    "    y_pred = tf.cast(y_pred, y_true.dtype)\n",
    "\n",
    "    match = tf.cast(y_true == y_pred, tf.float32)\n",
    "    mask = tf.cast(y_true != 0, tf.float32)\n",
    "\n",
    "    return tf.reduce_sum(match)/tf.reduce_sum(mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f541cf8-23a9-4dc7-b2a6-2a71293d7a20",
   "metadata": {},
   "source": [
    "# Compile and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4ea05d9d-b480-42b9-85bb-e7509eff5285",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatBot(vectorizer, UNITS, EMBEDDING_DIMS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7067ba74-31a8-4872-b12d-851b4474c2c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=masked_loss, \n",
    "              metrics=[masked_acc, masked_loss])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e72f685c-28cb-4477-8aa7-6d45784a35f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 10\n",
    "\n",
    "CKPT_DIR = './model_checkpoint'\n",
    "# CKPT_DIR = '/content/drive/MyDrive/tf_model/chatbot'\n",
    "os.makedirs(CKPT_DIR, exist_ok = True)\n",
    "model_ckpt = tf.keras.callbacks.ModelCheckpoint(\n",
    "    os.path.join(CKPT_DIR,  f\"{datetime.now().strftime('%m:%d:%Y, %H:%M:%S')}\"),\n",
    "    monitor= 'masked_acc',\n",
    "    verbose= 0,\n",
    "    save_best_only = True,\n",
    "    save_weights_only = True,\n",
    "    mode= 'auto',\n",
    "    save_freq='epoch'\n",
    ")\n",
    "\n",
    "os.makedirs('log', exist_ok = True)\n",
    "csv_logger = CSVLogger('./log/training.log')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfcfa8af-e58d-41ed-896b-25686db9f034",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-26 19:58:59.738615: W tensorflow/core/common_runtime/type_inference.cc:339] Type inference failed. This indicates an invalid graph that escaped type checking. Error message: INVALID_ARGUMENT: expected compatible input types, but input 1:\n",
      "type_id: TFT_OPTIONAL\n",
      "args {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_TENSOR\n",
      "    args {\n",
      "      type_id: TFT_INT32\n",
      "    }\n",
      "  }\n",
      "}\n",
      " is neither a subtype nor a supertype of the combined inputs preceding it:\n",
      "type_id: TFT_OPTIONAL\n",
      "args {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_TENSOR\n",
      "    args {\n",
      "      type_id: TFT_INT8\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "\twhile inferring type of node 'cond_41/output/_22'\n",
      "2023-02-26 19:59:00.745011: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8100\n",
      "2023-02-26 19:59:02.171648: I tensorflow/compiler/xla/service/service.cc:173] XLA service 0x1c48e970 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-02-26 19:59:02.171709: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (0): NVIDIA GeForce GTX 1650, Compute Capability 7.5\n",
      "2023-02-26 19:59:02.206474: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-02-26 19:59:02.371996: W tensorflow/compiler/xla/service/gpu/nvptx_helper.cc:56] Can't find libdevice directory ${CUDA_DIR}/nvvm/libdevice. This may result in compilation or runtime failures, if the program we try to run uses routines from libdevice.\n",
      "Searched for CUDA in the following directories:\n",
      "  ./cuda_sdk_lib\n",
      "  /usr/local/cuda-11.2\n",
      "  /usr/local/cuda\n",
      "  .\n",
      "You can choose the search directory by setting xla_gpu_cuda_data_dir in HloModule's DebugOptions.  For most apps, setting the environment variable XLA_FLAGS=--xla_gpu_cuda_data_dir=/path/to/cuda will work.\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "history = model.fit(\n",
    "    train_data.repeat(), \n",
    "    epochs=EPOCHS,\n",
    "    steps_per_epoch = 80,\n",
    "    validation_data=test_data,\n",
    "    validation_steps = 5,\n",
    "    callbacks=[\n",
    "                tf.keras.callbacks.EarlyStopping(patience=5),\n",
    "                model_ckpt,\n",
    "                csv_logger]\n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efa3096e-6f18-465a-ba4f-72cb3af03086",
   "metadata": {},
   "source": [
    "# Translate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec71adf-c81f-45a2-a0e6-46cbe8cbfaff",
   "metadata": {},
   "outputs": [],
   "source": [
    "@ChatBot.add_method\n",
    "def translate(self,\n",
    "              texts, *,\n",
    "              max_length=50,\n",
    "              temperature=0.0):\n",
    "    # Process the input texts\n",
    "    context = self.encoder.convert_input(texts, return_state = True)\n",
    "\n",
    "    context, state = context\n",
    "    fw_state, bw_state = state\n",
    "    batch_size = tf.shape(texts)[0]\n",
    "\n",
    "    # Setup the loop inputs\n",
    "    tokens = []\n",
    "    attention_weights = []\n",
    "    next_token, done, state = self.decoder.get_initial_state(context)\n",
    "    state = bw_state\n",
    "    # state =[state,state]\n",
    "    for _ in range(max_length):\n",
    "        # Generate the next token\n",
    "        next_token, done, state = self.decoder.get_next_token(\n",
    "                next_token, context, done,  state, temperature)\n",
    "\n",
    "        # Collect the generated tokens\n",
    "        tokens.append(next_token)\n",
    "        attention_weights.append(self.decoder.last_attention_weights)\n",
    "\n",
    "        if tf.executing_eagerly() and tf.reduce_all(done):\n",
    "            break\n",
    "\n",
    "    # Stack the lists of tokens and attention weights.\n",
    "    tokens = tf.concat(tokens, axis=-1)   # t*[(batch 1)] -> (batch, t)\n",
    "    self.last_attention_weights = tf.concat(attention_weights, axis=1)  # t*[(batch 1 s)] -> (batch, t s)\n",
    "\n",
    "    result = self.decoder.tokens_to_text(tokens)\n",
    "    return result, tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7709f55-9f9f-4d37-b071-975678c5e045",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4edd67c-a52a-4dae-97ad-7492a234d26b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cc8e7f2-b6fe-4782-941f-dfffb8e060a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c7934f0-9567-4cc8-a07a-0c956220e124",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c09f75-88d5-4dc4-9a42-398b7a17a4d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b586d8e-0b41-4f2c-b20a-f6e05aa051dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7447dbf-c935-4080-8230-c827a38e98d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d52f1642-700a-42ec-900f-41c19dc9cf97",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f40775f-25aa-45e9-9b2c-5ef2a47bafee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8add436-3533-41ca-b864-63a85f5a30c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4158bb21-094d-4bd9-bf1f-8a209d980676",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de4b7996-8c34-4c51-a707-60caf8921a84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f366abef-cd80-42bb-b680-ad634d234eb9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d8fb6b-0362-4a39-b06b-af08bee0cf6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13198b71-3dcf-4218-94b1-994db06e7b89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f98e0ed1-7a81-4793-91a1-6839b9864bd8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61097607-493e-4ada-979b-492f874d0ded",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_new",
   "language": "python",
   "name": "tf_new"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
